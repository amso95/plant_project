{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.applications import EfficientNetB0, ResNet50, VGG16\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import RandomFlip, RandomRotation, RandomZoom\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import mixed_precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = [\"aloevera\", \"banana\", \"bilimbi\", \"cantaloupe\", \"cassava\", \"coconut\", \"corn\", \"cucumber\",\n",
    "            \"curcuma\", \"eggplant\", \"galangal\", \"ginger\", \"guava\", \"kale\", \"longbeans\", \"mango\", \"melon\",\n",
    "            \"orange\", \"paddy\", \"papaya\", \"peper chili\", \"pineapple\", \"pomelo\", \"shallot\", \"soybeans\",\n",
    "            \"spinach\", \"sweet potatoes\", \"tobacco\", \"waterapple\", \"watermelon\"]\n",
    "width = 128\n",
    "height = 128\n",
    "path_train_folder = r'data\\split_ttv_dataset_type_of_plants\\Train_Set_Folder'\n",
    "path_validation_folder = r'data\\split_ttv_dataset_type_of_plants\\Validation_Set_Folder' \n",
    "path_test_folder = r'data\\split_ttv_dataset_type_of_plants\\Test_Set_Folder'\n",
    "num_labels = len(emotions)\n",
    "\n",
    "# Enable mixed precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# Define paths\n",
    "train_dir = r'data\\split_ttv_dataset_type_of_plants\\Train_Set_Folder'\n",
    "validation_dir = r'data\\split_ttv_dataset_type_of_plants\\Validation_Set_Folder' \n",
    "test_dir = r'data\\split_ttv_dataset_type_of_plants\\Test_Set_Folder'\n",
    "\n",
    "# Parameters\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 30 # 1081\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23972 files belonging to 30 classes.\n",
      "Found 3030 files belonging to 30 classes.\n",
      "Found 2998 files belonging to 30 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create datasets\n",
    "train_dataset = image_dataset_from_directory(\n",
    "\ttrain_dir,\n",
    "\tlabels='inferred',\n",
    "\tlabel_mode='categorical',\n",
    "\tbatch_size=BATCH_SIZE,\n",
    "\timage_size=IMG_SIZE,\n",
    "\tshuffle=True,\n",
    "\tseed=123\n",
    ")\n",
    "\n",
    "validation_dataset = image_dataset_from_directory(\n",
    "\tvalidation_dir,\n",
    "\tlabels='inferred',\n",
    "\tlabel_mode='categorical',\n",
    "\tbatch_size=BATCH_SIZE,\n",
    "\timage_size=IMG_SIZE,\n",
    "\tshuffle=True,\n",
    "\tseed=123\n",
    ")\n",
    "\n",
    "test_dataset = image_dataset_from_directory(\n",
    "\ttest_dir,\n",
    "\tlabels='inferred',\n",
    "\tlabel_mode='categorical',\n",
    "\tbatch_size=BATCH_SIZE,\n",
    "\timage_size=IMG_SIZE,\n",
    "\tshuffle=False\n",
    ")\n",
    "\n",
    "# Prefetch\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# Compute class weights\n",
    "train_labels = []\n",
    "for _, labels in train_dataset.unbatch():\n",
    "\ttrain_labels.append(np.argmax(labels.numpy()))\n",
    "\n",
    "class_weights_values = class_weight.compute_class_weight(\n",
    "\tclass_weight='balanced',\n",
    "\tclasses=np.unique(train_labels),\n",
    "\ty=train_labels\n",
    ")\n",
    "\n",
    "class_weights = {i: weight for i, weight in enumerate(class_weights_values)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Data Augmentation\n",
    "data_augmentation = Sequential([\n",
    "\tRandomFlip(\"horizontal_and_vertical\"),\n",
    "\tRandomRotation(0.2),\n",
    "\tRandomZoom(0.2),\n",
    "])\n",
    "\n",
    "# Build the model\n",
    "base_model = VGG16(\n",
    "\tweights='imagenet',\n",
    "\tinclude_top=False,\n",
    "\tinput_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)\n",
    ")\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model with data augmentation\n",
    "input_layer = layers.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "x = data_augmentation(input_layer)\n",
    "x = base_model(x, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "output_layer = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "model = models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "\toptimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "\tloss='categorical_crossentropy',\n",
    "\tmetrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "\tmonitor='val_accuracy',\n",
    "\tpatience=10,\n",
    "\trestore_best_weights=True\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "\t'best_model.keras',\n",
    "\tmonitor='val_accuracy',\n",
    "\tsave_best_only=True,\n",
    "\tverbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "\tmonitor='val_accuracy',\n",
    "\tfactor=0.2,\n",
    "\tpatience=5,\n",
    "\tverbose=1,\n",
    "\tmin_lr=1e-7\n",
    ")\n",
    "\n",
    "callbacks = [early_stopping, checkpoint, reduce_lr]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.0506 - loss: 4.6777\n",
      "Epoch 1: val_accuracy did not improve from 0.92970\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2925s\u001b[0m 4s/step - accuracy: 0.0506 - loss: 4.6770 - val_accuracy: 0.2564 - val_loss: 2.7527 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.1843 - loss: 3.1951\n",
      "Epoch 2: val_accuracy did not improve from 0.92970\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3493s\u001b[0m 5s/step - accuracy: 0.1843 - loss: 3.1948 - val_accuracy: 0.4587 - val_loss: 1.9318 - learning_rate: 1.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.3126 - loss: 2.5067\n",
      "Epoch 3: val_accuracy did not improve from 0.92970\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3553s\u001b[0m 5s/step - accuracy: 0.3126 - loss: 2.5066 - val_accuracy: 0.5660 - val_loss: 1.5450 - learning_rate: 1.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.3956 - loss: 2.1397\n",
      "Epoch 4: val_accuracy did not improve from 0.92970\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3611s\u001b[0m 5s/step - accuracy: 0.3956 - loss: 2.1396 - val_accuracy: 0.6287 - val_loss: 1.3189 - learning_rate: 1.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.4558 - loss: 1.9024\n",
      "Epoch 5: val_accuracy did not improve from 0.92970\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3428s\u001b[0m 5s/step - accuracy: 0.4559 - loss: 1.9024 - val_accuracy: 0.6660 - val_loss: 1.1773 - learning_rate: 1.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.5021 - loss: 1.7230\n",
      "Epoch 6: val_accuracy did not improve from 0.92970\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4403s\u001b[0m 6s/step - accuracy: 0.5021 - loss: 1.7230 - val_accuracy: 0.6941 - val_loss: 1.0749 - learning_rate: 1.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.5323 - loss: 1.5975\n",
      "Epoch 7: val_accuracy did not improve from 0.92970\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5003s\u001b[0m 7s/step - accuracy: 0.5323 - loss: 1.5975 - val_accuracy: 0.7125 - val_loss: 0.9975 - learning_rate: 1.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.5540 - loss: 1.5219\n",
      "Epoch 8: val_accuracy did not improve from 0.92970\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4696s\u001b[0m 6s/step - accuracy: 0.5540 - loss: 1.5218 - val_accuracy: 0.7267 - val_loss: 0.9429 - learning_rate: 1.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.5743 - loss: 1.4546\n",
      "Epoch 9: val_accuracy did not improve from 0.92970\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3977s\u001b[0m 5s/step - accuracy: 0.5743 - loss: 1.4546 - val_accuracy: 0.7396 - val_loss: 0.8954 - learning_rate: 1.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.5932 - loss: 1.3706\n",
      "Epoch 10: val_accuracy did not improve from 0.92970\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4002s\u001b[0m 5s/step - accuracy: 0.5932 - loss: 1.3706 - val_accuracy: 0.7525 - val_loss: 0.8568 - learning_rate: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "EPOCHS = 30\n",
    "history = model.fit(\n",
    "\ttrain_dataset,\n",
    "\tepochs=EPOCHS,\n",
    "\tvalidation_data=validation_dataset,\n",
    "\tcallbacks=callbacks,\n",
    "\tclass_weight=class_weights\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning\n",
    "base_model.trainable = True\n",
    "fine_tune_at = len(base_model.layers) - 20\n",
    "\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "\tlayer.trainable = False\n",
    "\n",
    "model.compile(\n",
    "\toptimizer=optimizers.Adam(learning_rate=1e-5),\n",
    "\tloss='categorical_crossentropy',\n",
    "\tmetrics=['accuracy']\n",
    ")\n",
    "\n",
    "fine_tune_epochs = 10\n",
    "total_epochs = EPOCHS + fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(\n",
    "\ttrain_dataset,\n",
    "\tepochs=total_epochs,\n",
    "\tinitial_epoch=history.epoch[-1],\n",
    "\tvalidation_data=validation_dataset,\n",
    "\tcallbacks=callbacks,\n",
    "\tclass_weight=class_weights\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 3s/step - accuracy: 0.2253 - loss: 2.8648\n",
      "Test Accuracy: 25.22%\n"
     ]
    }
   ],
   "source": [
    "# Load the best model\n",
    "#model.load_weights('best_model.keras')\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"transfer_learning_VGG16.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "for images, labels in test_dataset:\n",
    "\tpreds = model.predict(images)\n",
    "\ty_pred.extend(np.argmax(preds, axis=1))\n",
    "\ty_true.extend(np.argmax(labels.numpy(), axis=1))\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=train_dataset.class_names)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot misclassified images\n",
    "def plot_misclassified(images, true_labels, pred_labels, class_names, num=5):\n",
    "\tplt.figure(figsize=(15, 15))\n",
    "\tfor i in range(num):\n",
    "\t\tplt.subplot(1, num, i+1)\n",
    "\t\tplt.imshow(images[i].astype(\"uint8\"))\n",
    "\t\tplt.title(f\"True: {class_names[true_labels[i]]}\\nPred: {class_names[pred_labels[i]]}\")\n",
    "\t\tplt.axis('off')\n",
    "\tplt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect misclassified examples\n",
    "misclassified_images = []\n",
    "misclassified_true = []\n",
    "misclassified_pred = []\n",
    "\n",
    "for images, labels in test_dataset:\n",
    "\tpreds = model.predict(images)\n",
    "\tpreds = np.argmax(preds, axis=1)\n",
    "\ttrue = np.argmax(labels.numpy(), axis=1)\n",
    "\tfor img, t, p in zip(images, true, preds):\n",
    "\t\tif t != p:\n",
    "\t\t\tmisclassified_images.append(img.numpy())\n",
    "\t\t\tmisclassified_true.append(t)\n",
    "\t\t\tmisclassified_pred.append(p)\n",
    "\t\tif len(misclassified_images) >= 5:\n",
    "\t\t\tbreak\n",
    "\t\tif len(misclassified_images) >= 5:\n",
    "\t\t\tbreak\n",
    "\n",
    "# Plot misclassified images\n",
    "plot_misclassified(\n",
    "\tmisclassified_images,\n",
    "\tmisclassified_true,\n",
    "\tmisclassified_pred,\n",
    "\ttrain_dataset.class_names,\n",
    "\tnum=5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('efficientnet_plant_classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
