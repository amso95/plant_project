{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import RandomFlip, RandomRotation, RandomZoom\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import mixed_precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = [\"aloevera\", \"banana\", \"bilimbi\", \"cantaloupe\", \"cassava\", \"coconut\", \"corn\", \"cucumber\",\n",
    "            \"curcuma\", \"eggplant\", \"galangal\", \"ginger\", \"guava\", \"kale\", \"longbeans\", \"mango\", \"melon\",\n",
    "            \"orange\", \"paddy\", \"papaya\", \"peper chili\", \"pineapple\", \"pomelo\", \"shallot\", \"soybeans\",\n",
    "            \"spinach\", \"sweet potatoes\", \"tobacco\", \"waterapple\", \"watermelon\"]\n",
    "width = 128\n",
    "height = 128\n",
    "path_train_folder = r'data\\split_ttv_dataset_type_of_plants\\Train_Set_Folder'\n",
    "path_validation_folder = r'data\\split_ttv_dataset_type_of_plants\\Validation_Set_Folder' \n",
    "path_test_folder = r'data\\split_ttv_dataset_type_of_plants\\Test_Set_Folder'\n",
    "num_labels = len(emotions)\n",
    "\n",
    "# Enable mixed precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# Define paths\n",
    "train_dir = r'data\\split_ttv_dataset_type_of_plants\\Train_Set_Folder'\n",
    "validation_dir = r'data\\split_ttv_dataset_type_of_plants\\Validation_Set_Folder' \n",
    "test_dir = r'data\\split_ttv_dataset_type_of_plants\\Test_Set_Folder'\n",
    "\n",
    "# Parameters\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 30 # 1081\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23972 files belonging to 30 classes.\n",
      "Found 3030 files belonging to 30 classes.\n",
      "Found 2998 files belonging to 30 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create datasets\n",
    "train_dataset = image_dataset_from_directory(\n",
    "\ttrain_dir,\n",
    "\tlabels='inferred',\n",
    "\tlabel_mode='categorical',\n",
    "\tbatch_size=BATCH_SIZE,\n",
    "\timage_size=IMG_SIZE,\n",
    "\tshuffle=True,\n",
    "\tseed=123\n",
    ")\n",
    "\n",
    "validation_dataset = image_dataset_from_directory(\n",
    "\tvalidation_dir,\n",
    "\tlabels='inferred',\n",
    "\tlabel_mode='categorical',\n",
    "\tbatch_size=BATCH_SIZE,\n",
    "\timage_size=IMG_SIZE,\n",
    "\tshuffle=True,\n",
    "\tseed=123\n",
    ")\n",
    "\n",
    "test_dataset = image_dataset_from_directory(\n",
    "\ttest_dir,\n",
    "\tlabels='inferred',\n",
    "\tlabel_mode='categorical',\n",
    "\tbatch_size=BATCH_SIZE,\n",
    "\timage_size=IMG_SIZE,\n",
    "\tshuffle=False\n",
    ")\n",
    "\n",
    "# Prefetch\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# Compute class weights\n",
    "train_labels = []\n",
    "for _, labels in train_dataset.unbatch():\n",
    "\ttrain_labels.append(np.argmax(labels.numpy()))\n",
    "\n",
    "class_weights_values = class_weight.compute_class_weight(\n",
    "\tclass_weight='balanced',\n",
    "\tclasses=np.unique(train_labels),\n",
    "\ty=train_labels\n",
    ")\n",
    "\n",
    "class_weights = {i: weight for i, weight in enumerate(class_weights_values)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Data Augmentation\n",
    "data_augmentation = Sequential([\n",
    "\tRandomFlip(\"horizontal_and_vertical\"),\n",
    "\tRandomRotation(0.2),\n",
    "\tRandomZoom(0.2),\n",
    "])\n",
    "\n",
    "# Build the model\n",
    "base_model = EfficientNetB0(\n",
    "\tweights='imagenet',\n",
    "\tinclude_top=False,\n",
    "\tinput_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)\n",
    ")\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model with data augmentation\n",
    "input_layer = layers.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "x = data_augmentation(input_layer)\n",
    "x = base_model(x, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "output_layer = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "model = models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "\toptimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "\tloss='categorical_crossentropy',\n",
    "\tmetrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "\tmonitor='val_accuracy',\n",
    "\tpatience=10,\n",
    "\trestore_best_weights=True\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "\t'best_model.keras',\n",
    "\tmonitor='val_accuracy',\n",
    "\tsave_best_only=True,\n",
    "\tverbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "\tmonitor='val_accuracy',\n",
    "\tfactor=0.2,\n",
    "\tpatience=5,\n",
    "\tverbose=1,\n",
    "\tmin_lr=1e-7\n",
    ")\n",
    "\n",
    "callbacks = [early_stopping, checkpoint, reduce_lr]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.1477 - loss: 3.7786\n",
      "Epoch 1: val_accuracy improved from -inf to 0.67987, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1352s\u001b[0m 2s/step - accuracy: 0.1479 - loss: 3.7775 - val_accuracy: 0.6799 - val_loss: 1.1112 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5151 - loss: 1.6657\n",
      "Epoch 2: val_accuracy improved from 0.67987 to 0.79241, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1710s\u001b[0m 2s/step - accuracy: 0.5152 - loss: 1.6656 - val_accuracy: 0.7924 - val_loss: 0.7064 - learning_rate: 1.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6416 - loss: 1.2085\n",
      "Epoch 3: val_accuracy improved from 0.79241 to 0.82805, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1745s\u001b[0m 2s/step - accuracy: 0.6416 - loss: 1.2084 - val_accuracy: 0.8281 - val_loss: 0.5560 - learning_rate: 1.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6976 - loss: 0.9973\n",
      "Epoch 4: val_accuracy improved from 0.82805 to 0.85413, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1719s\u001b[0m 2s/step - accuracy: 0.6976 - loss: 0.9973 - val_accuracy: 0.8541 - val_loss: 0.4738 - learning_rate: 1.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7318 - loss: 0.8690\n",
      "Epoch 5: val_accuracy improved from 0.85413 to 0.87030, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1766s\u001b[0m 2s/step - accuracy: 0.7318 - loss: 0.8690 - val_accuracy: 0.8703 - val_loss: 0.4161 - learning_rate: 1.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7537 - loss: 0.7957\n",
      "Epoch 6: val_accuracy improved from 0.87030 to 0.87921, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1531s\u001b[0m 2s/step - accuracy: 0.7537 - loss: 0.7957 - val_accuracy: 0.8792 - val_loss: 0.3795 - learning_rate: 1.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7823 - loss: 0.7082\n",
      "Epoch 7: val_accuracy improved from 0.87921 to 0.88944, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1520s\u001b[0m 2s/step - accuracy: 0.7823 - loss: 0.7082 - val_accuracy: 0.8894 - val_loss: 0.3487 - learning_rate: 1.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7929 - loss: 0.6615\n",
      "Epoch 8: val_accuracy improved from 0.88944 to 0.89472, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1513s\u001b[0m 2s/step - accuracy: 0.7929 - loss: 0.6615 - val_accuracy: 0.8947 - val_loss: 0.3243 - learning_rate: 1.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7977 - loss: 0.6365\n",
      "Epoch 9: val_accuracy improved from 0.89472 to 0.90297, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1706s\u001b[0m 2s/step - accuracy: 0.7977 - loss: 0.6364 - val_accuracy: 0.9030 - val_loss: 0.3040 - learning_rate: 1.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8062 - loss: 0.5995\n",
      "Epoch 10: val_accuracy improved from 0.90297 to 0.90594, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1710s\u001b[0m 2s/step - accuracy: 0.8062 - loss: 0.5995 - val_accuracy: 0.9059 - val_loss: 0.2850 - learning_rate: 1.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8171 - loss: 0.5703\n",
      "Epoch 11: val_accuracy improved from 0.90594 to 0.91122, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1709s\u001b[0m 2s/step - accuracy: 0.8171 - loss: 0.5703 - val_accuracy: 0.9112 - val_loss: 0.2707 - learning_rate: 1.0000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8277 - loss: 0.5380\n",
      "Epoch 12: val_accuracy improved from 0.91122 to 0.91683, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1519s\u001b[0m 2s/step - accuracy: 0.8277 - loss: 0.5380 - val_accuracy: 0.9168 - val_loss: 0.2590 - learning_rate: 1.0000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8298 - loss: 0.5320\n",
      "Epoch 13: val_accuracy improved from 0.91683 to 0.92178, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1542s\u001b[0m 2s/step - accuracy: 0.8298 - loss: 0.5320 - val_accuracy: 0.9218 - val_loss: 0.2482 - learning_rate: 1.0000e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8349 - loss: 0.5099\n",
      "Epoch 14: val_accuracy improved from 0.92178 to 0.92244, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1716s\u001b[0m 2s/step - accuracy: 0.8349 - loss: 0.5099 - val_accuracy: 0.9224 - val_loss: 0.2398 - learning_rate: 1.0000e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8432 - loss: 0.4951\n",
      "Epoch 15: val_accuracy improved from 0.92244 to 0.92607, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1512s\u001b[0m 2s/step - accuracy: 0.8432 - loss: 0.4951 - val_accuracy: 0.9261 - val_loss: 0.2325 - learning_rate: 1.0000e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8456 - loss: 0.4823\n",
      "Epoch 16: val_accuracy improved from 0.92607 to 0.92706, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1323s\u001b[0m 2s/step - accuracy: 0.8456 - loss: 0.4823 - val_accuracy: 0.9271 - val_loss: 0.2248 - learning_rate: 1.0000e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8529 - loss: 0.4642\n",
      "Epoch 17: val_accuracy improved from 0.92706 to 0.93003, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1324s\u001b[0m 2s/step - accuracy: 0.8529 - loss: 0.4642 - val_accuracy: 0.9300 - val_loss: 0.2208 - learning_rate: 1.0000e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8495 - loss: 0.4603\n",
      "Epoch 18: val_accuracy improved from 0.93003 to 0.93267, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1322s\u001b[0m 2s/step - accuracy: 0.8495 - loss: 0.4603 - val_accuracy: 0.9327 - val_loss: 0.2166 - learning_rate: 1.0000e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8540 - loss: 0.4465\n",
      "Epoch 19: val_accuracy did not improve from 0.93267\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1324s\u001b[0m 2s/step - accuracy: 0.8540 - loss: 0.4465 - val_accuracy: 0.9310 - val_loss: 0.2094 - learning_rate: 1.0000e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8579 - loss: 0.4345\n",
      "Epoch 20: val_accuracy did not improve from 0.93267\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1325s\u001b[0m 2s/step - accuracy: 0.8579 - loss: 0.4345 - val_accuracy: 0.9323 - val_loss: 0.2056 - learning_rate: 1.0000e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8598 - loss: 0.4338\n",
      "Epoch 21: val_accuracy improved from 0.93267 to 0.93564, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1324s\u001b[0m 2s/step - accuracy: 0.8598 - loss: 0.4338 - val_accuracy: 0.9356 - val_loss: 0.2003 - learning_rate: 1.0000e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8660 - loss: 0.4153\n",
      "Epoch 22: val_accuracy did not improve from 0.93564\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1328s\u001b[0m 2s/step - accuracy: 0.8660 - loss: 0.4153 - val_accuracy: 0.9350 - val_loss: 0.1979 - learning_rate: 1.0000e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8632 - loss: 0.4206\n",
      "Epoch 23: val_accuracy improved from 0.93564 to 0.93894, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1325s\u001b[0m 2s/step - accuracy: 0.8632 - loss: 0.4206 - val_accuracy: 0.9389 - val_loss: 0.1923 - learning_rate: 1.0000e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8660 - loss: 0.4128\n",
      "Epoch 24: val_accuracy did not improve from 0.93894\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1326s\u001b[0m 2s/step - accuracy: 0.8659 - loss: 0.4129 - val_accuracy: 0.9373 - val_loss: 0.1899 - learning_rate: 1.0000e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8654 - loss: 0.4078\n",
      "Epoch 25: val_accuracy improved from 0.93894 to 0.93927, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1325s\u001b[0m 2s/step - accuracy: 0.8654 - loss: 0.4078 - val_accuracy: 0.9393 - val_loss: 0.1854 - learning_rate: 1.0000e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8659 - loss: 0.4088\n",
      "Epoch 26: val_accuracy improved from 0.93927 to 0.93993, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1529s\u001b[0m 2s/step - accuracy: 0.8659 - loss: 0.4088 - val_accuracy: 0.9399 - val_loss: 0.1821 - learning_rate: 1.0000e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8648 - loss: 0.4076\n",
      "Epoch 27: val_accuracy improved from 0.93993 to 0.94224, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1514s\u001b[0m 2s/step - accuracy: 0.8648 - loss: 0.4076 - val_accuracy: 0.9422 - val_loss: 0.1792 - learning_rate: 1.0000e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8695 - loss: 0.3991\n",
      "Epoch 28: val_accuracy improved from 0.94224 to 0.94290, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1522s\u001b[0m 2s/step - accuracy: 0.8695 - loss: 0.3991 - val_accuracy: 0.9429 - val_loss: 0.1782 - learning_rate: 1.0000e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8711 - loss: 0.3922\n",
      "Epoch 29: val_accuracy improved from 0.94290 to 0.94422, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1529s\u001b[0m 2s/step - accuracy: 0.8711 - loss: 0.3922 - val_accuracy: 0.9442 - val_loss: 0.1745 - learning_rate: 1.0000e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8707 - loss: 0.3893\n",
      "Epoch 30: val_accuracy improved from 0.94422 to 0.94620, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1520s\u001b[0m 2s/step - accuracy: 0.8707 - loss: 0.3894 - val_accuracy: 0.9462 - val_loss: 0.1698 - learning_rate: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "EPOCHS = 30\n",
    "history = model.fit(\n",
    "\ttrain_dataset,\n",
    "\tepochs=EPOCHS,\n",
    "\tvalidation_data=validation_dataset,\n",
    "\tcallbacks=callbacks,\n",
    "\tclass_weight=class_weights\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning\n",
    "base_model.trainable = True\n",
    "fine_tune_at = len(base_model.layers) - 20\n",
    "\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "\tlayer.trainable = False\n",
    "\n",
    "model.compile(\n",
    "\toptimizer=optimizers.Adam(learning_rate=1e-5),\n",
    "\tloss='categorical_crossentropy',\n",
    "\tmetrics=['accuracy']\n",
    ")\n",
    "\n",
    "fine_tune_epochs = 10\n",
    "total_epochs = EPOCHS + fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(\n",
    "\ttrain_dataset,\n",
    "\tepochs=total_epochs,\n",
    "\tinitial_epoch=history.epoch[-1],\n",
    "\tvalidation_data=validation_dataset,\n",
    "\tcallbacks=callbacks,\n",
    "\tclass_weight=class_weights\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 2s/step - accuracy: 0.9411 - loss: 0.1672\n",
      "Test Accuracy: 94.40%\n"
     ]
    }
   ],
   "source": [
    "# Load the best model\n",
    "#model.load_weights('best_model.keras')\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "for images, labels in test_dataset:\n",
    "\tpreds = model.predict(images)\n",
    "\ty_pred.extend(np.argmax(preds, axis=1))\n",
    "\ty_true.extend(np.argmax(labels.numpy(), axis=1))\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=train_dataset.class_names)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot misclassified images\n",
    "def plot_misclassified(images, true_labels, pred_labels, class_names, num=5):\n",
    "\tplt.figure(figsize=(15, 15))\n",
    "\tfor i in range(num):\n",
    "\t\tplt.subplot(1, num, i+1)\n",
    "\t\tplt.imshow(images[i].astype(\"uint8\"))\n",
    "\t\tplt.title(f\"True: {class_names[true_labels[i]]}\\nPred: {class_names[pred_labels[i]]}\")\n",
    "\t\tplt.axis('off')\n",
    "\tplt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect misclassified examples\n",
    "misclassified_images = []\n",
    "misclassified_true = []\n",
    "misclassified_pred = []\n",
    "\n",
    "for images, labels in test_dataset:\n",
    "\tpreds = model.predict(images)\n",
    "\tpreds = np.argmax(preds, axis=1)\n",
    "\ttrue = np.argmax(labels.numpy(), axis=1)\n",
    "\tfor img, t, p in zip(images, true, preds):\n",
    "\t\tif t != p:\n",
    "\t\t\tmisclassified_images.append(img.numpy())\n",
    "\t\t\tmisclassified_true.append(t)\n",
    "\t\t\tmisclassified_pred.append(p)\n",
    "\t\tif len(misclassified_images) >= 5:\n",
    "\t\t\tbreak\n",
    "\t\tif len(misclassified_images) >= 5:\n",
    "\t\t\tbreak\n",
    "\n",
    "# Plot misclassified images\n",
    "plot_misclassified(\n",
    "\tmisclassified_images,\n",
    "\tmisclassified_true,\n",
    "\tmisclassified_pred,\n",
    "\ttrain_dataset.class_names,\n",
    "\tnum=5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('efficientnet_plant_classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
