{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.applications import EfficientNetB0,ResNet50\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import RandomFlip, RandomRotation, RandomZoom\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import mixed_precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = [\"aloevera\", \"banana\", \"bilimbi\", \"cantaloupe\", \"cassava\", \"coconut\", \"corn\", \"cucumber\",\n",
    "            \"curcuma\", \"eggplant\", \"galangal\", \"ginger\", \"guava\", \"kale\", \"longbeans\", \"mango\", \"melon\",\n",
    "            \"orange\", \"paddy\", \"papaya\", \"peper chili\", \"pineapple\", \"pomelo\", \"shallot\", \"soybeans\",\n",
    "            \"spinach\", \"sweet potatoes\", \"tobacco\", \"waterapple\", \"watermelon\"]\n",
    "width = 128\n",
    "height = 128\n",
    "path_train_folder = r'data\\split_ttv_dataset_type_of_plants\\Train_Set_Folder'\n",
    "path_validation_folder = r'data\\split_ttv_dataset_type_of_plants\\Validation_Set_Folder' \n",
    "path_test_folder = r'data\\split_ttv_dataset_type_of_plants\\Test_Set_Folder'\n",
    "num_labels = len(emotions)\n",
    "\n",
    "# Enable mixed precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# Define paths\n",
    "train_dir = r'data\\split_ttv_dataset_type_of_plants\\Train_Set_Folder'\n",
    "validation_dir = r'data\\split_ttv_dataset_type_of_plants\\Validation_Set_Folder' \n",
    "test_dir = r'data\\split_ttv_dataset_type_of_plants\\Test_Set_Folder'\n",
    "\n",
    "# Parameters\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 30 # 1081\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23972 files belonging to 30 classes.\n",
      "Found 3030 files belonging to 30 classes.\n",
      "Found 2998 files belonging to 30 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create datasets\n",
    "train_dataset = image_dataset_from_directory(\n",
    "\ttrain_dir,\n",
    "\tlabels='inferred',\n",
    "\tlabel_mode='categorical',\n",
    "\tbatch_size=BATCH_SIZE,\n",
    "\timage_size=IMG_SIZE,\n",
    "\tshuffle=True,\n",
    "\tseed=123\n",
    ")\n",
    "\n",
    "validation_dataset = image_dataset_from_directory(\n",
    "\tvalidation_dir,\n",
    "\tlabels='inferred',\n",
    "\tlabel_mode='categorical',\n",
    "\tbatch_size=BATCH_SIZE,\n",
    "\timage_size=IMG_SIZE,\n",
    "\tshuffle=True,\n",
    "\tseed=123\n",
    ")\n",
    "\n",
    "test_dataset = image_dataset_from_directory(\n",
    "\ttest_dir,\n",
    "\tlabels='inferred',\n",
    "\tlabel_mode='categorical',\n",
    "\tbatch_size=BATCH_SIZE,\n",
    "\timage_size=IMG_SIZE,\n",
    "\tshuffle=False\n",
    ")\n",
    "\n",
    "# Prefetch\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# Compute class weights\n",
    "train_labels = []\n",
    "for _, labels in train_dataset.unbatch():\n",
    "\ttrain_labels.append(np.argmax(labels.numpy()))\n",
    "\n",
    "class_weights_values = class_weight.compute_class_weight(\n",
    "\tclass_weight='balanced',\n",
    "\tclasses=np.unique(train_labels),\n",
    "\ty=train_labels\n",
    ")\n",
    "\n",
    "class_weights = {i: weight for i, weight in enumerate(class_weights_values)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Data Augmentation\n",
    "data_augmentation = Sequential([\n",
    "\tRandomFlip(\"horizontal_and_vertical\"),\n",
    "\tRandomRotation(0.2),\n",
    "\tRandomZoom(0.2),\n",
    "])\n",
    "\n",
    "# Build the model\n",
    "base_model = ResNet50(\n",
    "\tweights='imagenet',\n",
    "\tinclude_top=False,\n",
    "\tinput_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)\n",
    ")\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model with data augmentation\n",
    "input_layer = layers.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "x = data_augmentation(input_layer)\n",
    "x = base_model(x, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "output_layer = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "model = models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "\toptimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "\tloss='categorical_crossentropy',\n",
    "\tmetrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "\tmonitor='val_accuracy',\n",
    "\tpatience=10,\n",
    "\trestore_best_weights=True\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "\t'best_model.keras',\n",
    "\tmonitor='val_accuracy',\n",
    "\tsave_best_only=True,\n",
    "\tverbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "\tmonitor='val_accuracy',\n",
    "\tfactor=0.2,\n",
    "\tpatience=5,\n",
    "\tverbose=1,\n",
    "\tmin_lr=1e-7\n",
    ")\n",
    "\n",
    "callbacks = [early_stopping, checkpoint, reduce_lr]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.1607 - loss: 3.7416\n",
      "Epoch 1: val_accuracy improved from -inf to 0.64290, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1355s\u001b[0m 2s/step - accuracy: 0.1608 - loss: 3.7405 - val_accuracy: 0.6429 - val_loss: 1.2197 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5226 - loss: 1.6880\n",
      "Epoch 2: val_accuracy improved from 0.64290 to 0.74323, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1328s\u001b[0m 2s/step - accuracy: 0.5226 - loss: 1.6878 - val_accuracy: 0.7432 - val_loss: 0.8349 - learning_rate: 1.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6226 - loss: 1.2727\n",
      "Epoch 3: val_accuracy improved from 0.74323 to 0.79373, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1718s\u001b[0m 2s/step - accuracy: 0.6226 - loss: 1.2727 - val_accuracy: 0.7937 - val_loss: 0.6735 - learning_rate: 1.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6817 - loss: 1.0554\n",
      "Epoch 4: val_accuracy improved from 0.79373 to 0.81947, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1696s\u001b[0m 2s/step - accuracy: 0.6817 - loss: 1.0554 - val_accuracy: 0.8195 - val_loss: 0.5772 - learning_rate: 1.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7103 - loss: 0.9523\n",
      "Epoch 5: val_accuracy improved from 0.81947 to 0.83729, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1863s\u001b[0m 2s/step - accuracy: 0.7103 - loss: 0.9523 - val_accuracy: 0.8373 - val_loss: 0.5144 - learning_rate: 1.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7341 - loss: 0.8493\n",
      "Epoch 6: val_accuracy improved from 0.83729 to 0.85446, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1704s\u001b[0m 2s/step - accuracy: 0.7341 - loss: 0.8493 - val_accuracy: 0.8545 - val_loss: 0.4703 - learning_rate: 1.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7569 - loss: 0.7970\n",
      "Epoch 7: val_accuracy improved from 0.85446 to 0.86568, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1896s\u001b[0m 3s/step - accuracy: 0.7569 - loss: 0.7969 - val_accuracy: 0.8657 - val_loss: 0.4361 - learning_rate: 1.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7729 - loss: 0.7382\n",
      "Epoch 8: val_accuracy improved from 0.86568 to 0.87657, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1713s\u001b[0m 2s/step - accuracy: 0.7729 - loss: 0.7382 - val_accuracy: 0.8766 - val_loss: 0.4035 - learning_rate: 1.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7873 - loss: 0.6791\n",
      "Epoch 9: val_accuracy improved from 0.87657 to 0.87954, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1908s\u001b[0m 3s/step - accuracy: 0.7873 - loss: 0.6791 - val_accuracy: 0.8795 - val_loss: 0.3818 - learning_rate: 1.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7890 - loss: 0.6653\n",
      "Epoch 10: val_accuracy improved from 0.87954 to 0.88218, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1888s\u001b[0m 3s/step - accuracy: 0.7890 - loss: 0.6653 - val_accuracy: 0.8822 - val_loss: 0.3696 - learning_rate: 1.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7997 - loss: 0.6285\n",
      "Epoch 11: val_accuracy improved from 0.88218 to 0.89241, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1887s\u001b[0m 3s/step - accuracy: 0.7997 - loss: 0.6285 - val_accuracy: 0.8924 - val_loss: 0.3481 - learning_rate: 1.0000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8055 - loss: 0.6128\n",
      "Epoch 12: val_accuracy improved from 0.89241 to 0.89505, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1907s\u001b[0m 3s/step - accuracy: 0.8055 - loss: 0.6128 - val_accuracy: 0.8950 - val_loss: 0.3380 - learning_rate: 1.0000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8080 - loss: 0.5954\n",
      "Epoch 13: val_accuracy improved from 0.89505 to 0.89769, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1934s\u001b[0m 3s/step - accuracy: 0.8080 - loss: 0.5954 - val_accuracy: 0.8977 - val_loss: 0.3269 - learning_rate: 1.0000e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8217 - loss: 0.5621\n",
      "Epoch 14: val_accuracy improved from 0.89769 to 0.90297, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2131s\u001b[0m 3s/step - accuracy: 0.8217 - loss: 0.5620 - val_accuracy: 0.9030 - val_loss: 0.3098 - learning_rate: 1.0000e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8259 - loss: 0.5449\n",
      "Epoch 15: val_accuracy improved from 0.90297 to 0.90759, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1964s\u001b[0m 3s/step - accuracy: 0.8259 - loss: 0.5449 - val_accuracy: 0.9076 - val_loss: 0.3045 - learning_rate: 1.0000e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8309 - loss: 0.5322\n",
      "Epoch 16: val_accuracy improved from 0.90759 to 0.90924, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1941s\u001b[0m 3s/step - accuracy: 0.8309 - loss: 0.5322 - val_accuracy: 0.9092 - val_loss: 0.2943 - learning_rate: 1.0000e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8308 - loss: 0.5257\n",
      "Epoch 17: val_accuracy improved from 0.90924 to 0.91386, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1935s\u001b[0m 3s/step - accuracy: 0.8308 - loss: 0.5257 - val_accuracy: 0.9139 - val_loss: 0.2865 - learning_rate: 1.0000e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8340 - loss: 0.5086\n",
      "Epoch 18: val_accuracy improved from 0.91386 to 0.91419, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1723s\u001b[0m 2s/step - accuracy: 0.8340 - loss: 0.5086 - val_accuracy: 0.9142 - val_loss: 0.2818 - learning_rate: 1.0000e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8361 - loss: 0.5086\n",
      "Epoch 19: val_accuracy improved from 0.91419 to 0.91683, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1912s\u001b[0m 3s/step - accuracy: 0.8361 - loss: 0.5086 - val_accuracy: 0.9168 - val_loss: 0.2698 - learning_rate: 1.0000e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8401 - loss: 0.4982\n",
      "Epoch 20: val_accuracy did not improve from 0.91683\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1938s\u001b[0m 3s/step - accuracy: 0.8401 - loss: 0.4982 - val_accuracy: 0.9158 - val_loss: 0.2697 - learning_rate: 1.0000e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8406 - loss: 0.4979\n",
      "Epoch 21: val_accuracy improved from 0.91683 to 0.92013, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1901s\u001b[0m 3s/step - accuracy: 0.8406 - loss: 0.4979 - val_accuracy: 0.9201 - val_loss: 0.2603 - learning_rate: 1.0000e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8460 - loss: 0.4767\n",
      "Epoch 22: val_accuracy improved from 0.92013 to 0.92343, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1744s\u001b[0m 2s/step - accuracy: 0.8460 - loss: 0.4768 - val_accuracy: 0.9234 - val_loss: 0.2536 - learning_rate: 1.0000e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8516 - loss: 0.4598\n",
      "Epoch 23: val_accuracy did not improve from 0.92343\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1896s\u001b[0m 3s/step - accuracy: 0.8516 - loss: 0.4599 - val_accuracy: 0.9201 - val_loss: 0.2521 - learning_rate: 1.0000e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8525 - loss: 0.4647\n",
      "Epoch 24: val_accuracy did not improve from 0.92343\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1915s\u001b[0m 3s/step - accuracy: 0.8525 - loss: 0.4647 - val_accuracy: 0.9228 - val_loss: 0.2460 - learning_rate: 1.0000e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8544 - loss: 0.4554\n",
      "Epoch 25: val_accuracy improved from 0.92343 to 0.92706, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1889s\u001b[0m 3s/step - accuracy: 0.8543 - loss: 0.4555 - val_accuracy: 0.9271 - val_loss: 0.2397 - learning_rate: 1.0000e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8504 - loss: 0.4524\n",
      "Epoch 26: val_accuracy did not improve from 0.92706\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1886s\u001b[0m 3s/step - accuracy: 0.8504 - loss: 0.4524 - val_accuracy: 0.9221 - val_loss: 0.2390 - learning_rate: 1.0000e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8488 - loss: 0.4577\n",
      "Epoch 27: val_accuracy did not improve from 0.92706\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2032s\u001b[0m 3s/step - accuracy: 0.8488 - loss: 0.4577 - val_accuracy: 0.9248 - val_loss: 0.2335 - learning_rate: 1.0000e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8532 - loss: 0.4503\n",
      "Epoch 28: val_accuracy improved from 0.92706 to 0.92805, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2203s\u001b[0m 3s/step - accuracy: 0.8532 - loss: 0.4503 - val_accuracy: 0.9281 - val_loss: 0.2314 - learning_rate: 1.0000e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8510 - loss: 0.4527\n",
      "Epoch 29: val_accuracy did not improve from 0.92805\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2408s\u001b[0m 3s/step - accuracy: 0.8510 - loss: 0.4527 - val_accuracy: 0.9271 - val_loss: 0.2292 - learning_rate: 1.0000e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8557 - loss: 0.4354\n",
      "Epoch 30: val_accuracy improved from 0.92805 to 0.92970, saving model to best_model.keras\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2400s\u001b[0m 3s/step - accuracy: 0.8557 - loss: 0.4354 - val_accuracy: 0.9297 - val_loss: 0.2236 - learning_rate: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "EPOCHS = 30\n",
    "history = model.fit(\n",
    "\ttrain_dataset,\n",
    "\tepochs=EPOCHS,\n",
    "\tvalidation_data=validation_dataset,\n",
    "\tcallbacks=callbacks,\n",
    "\tclass_weight=class_weights\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning\n",
    "base_model.trainable = True\n",
    "fine_tune_at = len(base_model.layers) - 20\n",
    "\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "\tlayer.trainable = False\n",
    "\n",
    "model.compile(\n",
    "\toptimizer=optimizers.Adam(learning_rate=1e-5),\n",
    "\tloss='categorical_crossentropy',\n",
    "\tmetrics=['accuracy']\n",
    ")\n",
    "\n",
    "fine_tune_epochs = 10\n",
    "total_epochs = EPOCHS + fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(\n",
    "\ttrain_dataset,\n",
    "\tepochs=total_epochs,\n",
    "\tinitial_epoch=history.epoch[-1],\n",
    "\tvalidation_data=validation_dataset,\n",
    "\tcallbacks=callbacks,\n",
    "\tclass_weight=class_weights\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 4s/step - accuracy: 0.9164 - loss: 0.2348\n",
      "Test Accuracy: 92.46%\n"
     ]
    }
   ],
   "source": [
    "# Load the best model\n",
    "#model.load_weights('best_model.keras')\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"transfer_learning_ResNet50.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "for images, labels in test_dataset:\n",
    "\tpreds = model.predict(images)\n",
    "\ty_pred.extend(np.argmax(preds, axis=1))\n",
    "\ty_true.extend(np.argmax(labels.numpy(), axis=1))\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=train_dataset.class_names)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot misclassified images\n",
    "def plot_misclassified(images, true_labels, pred_labels, class_names, num=5):\n",
    "\tplt.figure(figsize=(15, 15))\n",
    "\tfor i in range(num):\n",
    "\t\tplt.subplot(1, num, i+1)\n",
    "\t\tplt.imshow(images[i].astype(\"uint8\"))\n",
    "\t\tplt.title(f\"True: {class_names[true_labels[i]]}\\nPred: {class_names[pred_labels[i]]}\")\n",
    "\t\tplt.axis('off')\n",
    "\tplt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect misclassified examples\n",
    "misclassified_images = []\n",
    "misclassified_true = []\n",
    "misclassified_pred = []\n",
    "\n",
    "for images, labels in test_dataset:\n",
    "\tpreds = model.predict(images)\n",
    "\tpreds = np.argmax(preds, axis=1)\n",
    "\ttrue = np.argmax(labels.numpy(), axis=1)\n",
    "\tfor img, t, p in zip(images, true, preds):\n",
    "\t\tif t != p:\n",
    "\t\t\tmisclassified_images.append(img.numpy())\n",
    "\t\t\tmisclassified_true.append(t)\n",
    "\t\t\tmisclassified_pred.append(p)\n",
    "\t\tif len(misclassified_images) >= 5:\n",
    "\t\t\tbreak\n",
    "\t\tif len(misclassified_images) >= 5:\n",
    "\t\t\tbreak\n",
    "\n",
    "# Plot misclassified images\n",
    "plot_misclassified(\n",
    "\tmisclassified_images,\n",
    "\tmisclassified_true,\n",
    "\tmisclassified_pred,\n",
    "\ttrain_dataset.class_names,\n",
    "\tnum=5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('efficientnet_plant_classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
